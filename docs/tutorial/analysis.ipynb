{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit growth models and extract growth statistics\n",
    "\n",
    "This tutorial demonstrates how to fit growth models and extract growth statistics using the growthcurves package.\n",
    "\n",
    "The analysis workflow includes:\n",
    "1. Generating or loading growth data\n",
    "2. Fitting **mechanistic** models (ODE-based, parametric)\n",
    "3. Fitting **phenomenological** models (parametric and non-parametric)\n",
    "4. Extracting growth statistics from all fits\n",
    "5. Saving results for visualization\n",
    "\n",
    "For visualization of the results, see the companion notebook:\n",
    "[`plotting.ipynb`](plotting.ipynb) (Visualize fitted growth curves, derivatives,\n",
    " and growth statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import growthcurves as gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing Functions\n",
    "\n",
    "The growthcurves package provides preprocessing utilities for common data corrections:\n",
    "\n",
    "- **`path_correct(N, path_length_cm)`**: Normalize OD measurements to 1 cm path length\n",
    "- **`blank_subtraction(N, blank)`**: Subtract blank/background measurements from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Example 1: Path length correction\n",
    "# Measurements taken with a 0.5 cm path length, normalized to 1 cm\n",
    "raw_od_measurements = np.array([0.25, 0.30, 0.35, 0.40])\n",
    "path_length = 0.5  # cm\n",
    "\n",
    "od_corrected = gc.path_correct(raw_od_measurements, path_length)\n",
    "\n",
    "print(\"Path Length Correction Example:\")\n",
    "print(f\"  Raw OD (0.5 cm path): {raw_od_measurements}\")\n",
    "print(f\"  Corrected OD (1 cm path): {od_corrected}\")\n",
    "print()\n",
    "\n",
    "# Example 2: Blank subtraction\n",
    "# Typical workflow: subtract blank measurements from sample N\n",
    "sample_data = np.array([0.500, 0.600, 0.700, 0.800])\n",
    "blank_data = np.array([0.050, 0.052, 0.048, 0.051])\n",
    "\n",
    "corrected_data = gc.blank_subtraction(sample_data, blank_data)\n",
    "\n",
    "print(\"Blank Subtraction Example:\")\n",
    "print(f\"  Sample OD: {sample_data}\")\n",
    "print(f\"  Blank OD:  {blank_data}\")\n",
    "print(f\"  Corrected: {corrected_data}\")\n",
    "print()\n",
    "\n",
    "# Example 3: Combined preprocessing workflow\n",
    "# Simulate a typical preprocessing pipeline\n",
    "raw_measurements = np.array([0.125, 0.150, 0.175, 0.200])\n",
    "blank_measurements = np.array([0.025, 0.025, 0.025, 0.025])\n",
    "path_length_cm = 0.5\n",
    "\n",
    "# Step 1: Path correction\n",
    "od_1cm = gc.path_correct(raw_measurements, path_length_cm)\n",
    "\n",
    "# Step 2: Blank subtraction\n",
    "od_corrected = gc.blank_subtraction(\n",
    "    od_1cm, gc.path_correct(blank_measurements, path_length_cm)\n",
    ")\n",
    "\n",
    "print(\"Combined Preprocessing Pipeline:\")\n",
    "print(f\"  Raw measurements (0.5 cm):     {raw_measurements}\")\n",
    "print(f\"  After path correction (1 cm):  {od_1cm}\")\n",
    "print(\n",
    "    f\"  Blank (corrected to 1 cm):{gc.path_correct(blank_measurements, path_length_cm)}\"\n",
    ")\n",
    "print(f\"  Final corrected OD:            {od_corrected}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate synthetic data\n",
    "\n",
    "This cell generates synthetic growth data from a clean logistic function.\n",
    "- time is modeled in hours, with measurements every 12 minutes (0.2 hours) for\n",
    "  a total of 440 points (88 hours).\n",
    "- We assume a lag of 30 hours, an intrinsic growth rate of 0.15 hour\u207b\u00b9,\n",
    "  and a carrying capacity of 0.45 OD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Generate synthetic growth N from logistic function\n",
    "np.random.seed(42)\n",
    "\n",
    "# Parameters for synthetic growth curve\n",
    "n_points = 440\n",
    "measurement_interval_minutes = 12\n",
    "t = np.array([(measurement_interval_minutes * n) / 60 for n in range(n_points)])\n",
    "\n",
    "\n",
    "def logistic_growth(t, baseline, N0, K, mu, lag):\n",
    "    \"\"\"Logistic growth model with smooth transition through lag phase\"\"\"\n",
    "    # Standard logistic formula centered at lag t\n",
    "    # This creates a smooth S-curve with inflection point at t = lag + (K - N0) / N0\n",
    "    factor = (K - N0) / N0\n",
    "    growth = K / (1 + factor * np.exp(-mu * (t - lag)))\n",
    "    return baseline + growth, lag + np.log(factor) / mu\n",
    "\n",
    "\n",
    "def get_logistic_growth_and_rate(t, K, N0, mu, lag):\n",
    "    \"\"\"\n",
    "    Returns (Population, Growth_Rate) at t t.\n",
    "    \"\"\"\n",
    "    (K - N0) / N0\n",
    "    p_t, _ = logistic_growth(t, 0, N0, K, mu, lag)\n",
    "    derivative = mu * p_t * (1 - (p_t / K))\n",
    "    return p_t, derivative\n",
    "\n",
    "\n",
    "def get_acceleration(t, K, N0, mu, lag):\n",
    "    \"\"\"\n",
    "    Returns the acceleration (second derivative) at t t.\n",
    "    \"\"\"\n",
    "    p_t, _ = get_logistic_growth_and_rate(t, K, N0, mu, lag)\n",
    "    accel = mu**2 * p_t * (1 - (p_t / K)) * (1 - (2 * p_t / K))\n",
    "    return accel\n",
    "\n",
    "\n",
    "def get_doubling_time(t, K, N0, mu, lag):\n",
    "    \"\"\"\n",
    "    Returns the instantaneous doubling t at t t.\n",
    "    \"\"\"\n",
    "    p_t, _ = get_logistic_growth_and_rate(t, K, N0, mu, lag)\n",
    "    with np.errstate(divide=\"ignore\"):\n",
    "        doubling_time = np.log(2) / (mu * (1 - (p_t / K)))\n",
    "    return doubling_time\n",
    "\n",
    "\n",
    "def log_transformed_derivative(t, K, N0, mu, lag):\n",
    "    # Calculate P(t) first\n",
    "    p_t, _ = get_logistic_growth_and_rate(t, K, N0, mu, lag)\n",
    "\n",
    "    # The derivative of ln(P) is mu * (1 - P/K)\n",
    "    log_der = mu * (1 - (p_t / K))\n",
    "\n",
    "    return log_der\n",
    "\n",
    "\n",
    "# Example: At the inflection point (where P = K/2)\n",
    "# log_der = mu * (1 - 0.5) = 0.5 * mu\n",
    "\n",
    "# Generate clean logistic curve\n",
    "K = 0.45\n",
    "mu = 0.15\n",
    "N0 = 0.05\n",
    "baseline = N0\n",
    "lag = 30.0\n",
    "N, t_inflec = logistic_growth(t, baseline=baseline, N0=N0, K=K, mu=mu, lag=lag)\n",
    "N = N.tolist()\n",
    "\n",
    "ax = pd.Series(N, index=t).plot(\n",
    "    title=\"Synthetic Growth Curve\", xlabel=\"Time (hours)\", ylabel=\"OD\"\n",
    ")\n",
    "_ = ax.vlines(\n",
    "    t_inflec,\n",
    "    ymin=N0,\n",
    "    ymax=K + baseline,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "der_inflec, p_inflec = mu * K / 4, (K / 2 + N0)\n",
    "_ = ax.annotate(\n",
    "    f\"Inflection Point\\nt={t_inflec:.2f}\\n\"\n",
    "    f\"$\\\\frac{{dP}}{{dt}}_{{inflection}}$={der_inflec:.5f}\",\n",
    "    xy=(t_inflec, p_inflec),\n",
    "    xytext=(t_inflec + 2, 0.15),\n",
    "    arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=.2\"),\n",
    ")\n",
    "delta_t = np.log(2 + np.sqrt(3)) / mu\n",
    "t_accel, p_accel = t_inflec - delta_t, K * (0.5 - np.sqrt(3) / 6)\n",
    "_ = ax.vlines(\n",
    "    t_accel,\n",
    "    ymin=N0,\n",
    "    ymax=K + baseline,\n",
    "    color=\"green\",\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "der_max = 1 / 6 * mu * K\n",
    "_ = ax.annotate(\n",
    "    f\"Mu max\\nt={t_accel:.2f}\\n$\\\\frac{{dP}}{{dt}}_{{max}}$={der_max:.5f}\",\n",
    "    xy=(t_accel, p_accel + baseline),  # Adjusted for baseline...\n",
    "    xytext=(t_accel - 22, 0.25),\n",
    "    arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=.2\"),\n",
    ")\n",
    "doubling_time_at_inflection = np.log(2) / (mu * (1 - (p_accel) / K))\n",
    "print(\n",
    "    \"Doubling t at maximum acceleration point \"\n",
    "    f\"(t={t_accel:.2f}): {doubling_time_at_inflection:.2f} hours\"\n",
    ")\n",
    "\n",
    "max_mu = mu * (1 - ((p_accel) / K))\n",
    "print(\n",
    "    \"Maximum specific growth rate (mu_max of log curve)\"\n",
    "    f\" at t={t_accel:.2f}: {max_mu:.5f} hour^-1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Growth Parameters Are Calculated\n",
    "\n",
    "The table below summarizes how the main reported growth statistics are calculated across model classes.\n",
    "\n",
    "| Output key | Meaning | How it is calculated |\n",
    "|---|---|---|\n",
    "| `max_od` | Maximum observed/fitted OD | Maximum OD over the valid data range |\n",
    "| `mu_max` | Maximum specific growth rate (\u03bc_max) | Maximum of `d(ln N)/dt` from the fitted model (or local fit for non-parametric) |\n",
    "| `intrinsic_growth_rate` | Intrinsic model rate parameter | For mechanistic models: fitted intrinsic `\u03bc`; for phenomenological/non-parametric: `None` |\n",
    "| `doubling_time` | Doubling time in hours | `ln(2) / mu_max` |\n",
    "| `time_at_umax` | Time at maximum specific growth | Time where `mu_max` reaches its maximum |\n",
    "| `od_at_umax` | OD at time of \u03bc_max | Model-predicted OD at `time_at_umax` |\n",
    "| `exp_phase_start`, `exp_phase_end` | Exponential phase boundaries | From threshold or tangent phase-boundary method in `extract_stats()` |\n",
    "| `model_rmse` | Fit error | RMSE between observed OD and model-predicted OD over the model fit window |\n",
    "\n",
    "For this tutorial:\n",
    "- Mechanistic comparisons use mechanistic parametric fits.\n",
    "- Phenomenological comparisons include both phenomenological parametric and non-parametric fits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract growth stats from the dataset\n",
    "\n",
    "The `extract_stats_from_fit()` function calculates these key metrics:\n",
    "\n",
    "- `max_od`: Maximum OD value within the fitted window\n",
    "- `mu_max`: **Observed** maximum specific growth rate \u03bc_max (hour\u207b\u00b9) - calculated from the fitted curve\n",
    "- `intrinsic_growth_rate`: **Model parameter** for intrinsic growth rate (parametric models only, `None` for non-parametric)\n",
    "- `doubling_time`: Time to double the population at peak growth (hours)\n",
    "- `exp_phase_start`: When exponential phase begins (hours)\n",
    "- `exp_phase_end`: When exponential phase ends (hours)\n",
    "- `time_at_umax`: Time when \u03bc reaches its maximum (hours)\n",
    "- `od_at_umax`: OD value at time of maximum \u03bc\n",
    "- `fit_t_min`: Start of fitting window (hours)\n",
    "- `fit_t_max`: End of fitting window (hours)\n",
    "- `fit_method`: Identifier for the method used\n",
    "- `model_rmse`: Root mean squared error\n",
    "\n",
    "Descriptive parameters are extracted from the fits. Where parameters are not extracted directly from the fitted model, they are calculated. The table below shows how different stats are calculated according to the different approaches:\n",
    "\n",
    "### MECHANISTIC MODELS\n",
    "\n",
    "| Name | Model | Equation | Exp Start | Exp End | Intrinsic \u03bc | \u03bc max | Carrying Capacity | Fit |\n",
    "|------|-------|----------|-----------|---------|-------------|-------|-------------------|-----|\n",
    "| Logistic | parametric | `dN/dt = \u03bc * (1 - N(t) / K) * N(t)` | threshold/<br>tangent | threshold/<br>tangent | \u03bc | max dln(N)/dt | K | entire curve |\n",
    "| Gompertz | parametric | `dN/dt = \u03bc * math.log(K / N(t)) * N(t)` | threshold/<br>tangent | threshold/<br>tangent | \u03bc | max dln(N)/dt | K | entire curve |\n",
    "| Richards | parametric | `dN/dt = \u03bc * (1 - (N(t) / K)**beta) * N(t)` | threshold/<br>tangent | threshold/<br>tangent | \u03bc | max dln(N)/dt | A | entire curve |\n",
    "| Baranyi | parametric | `dN/dt= \u03bc * math.exp(\u03bc * t) / (math.exp(h0) - 1 + math.exp(\u03bc * t)) * (1 - N(t) / K) * N(t)` | threshold/<br>tangent | threshold/<br>tangent | \u03bc | max dln(N)/dt | K | entire curve |\n",
    "\n",
    "### PHENOMENOLOGICAL MODELS\n",
    "\n",
    "| Name | Model | Equation | Exp Start | Exp End | Intrinsic \u03bc | \u03bc max | Max OD | Fit |\n",
    "|------|-------|----------|-----------|---------|-------------|-------|--------|-----|\n",
    "| Linear | non-parametric | `ln(N(t)) = N0 + b * t` | threshold/<br>tangent | threshold/<br>tangent | n.a. | b | max OD raw | only window |\n",
    "| Spline | non-parametric | `ln(N(t)) = spline(t)` | threshold/<br>tangent | threshold/<br>tangent | n.a. | max of derivative of spline | max OD raw | only log phase |\n",
    "| Logistic (phenom) | parametric | `ln(N(t)/N0) = A / (1 + exp(4 * \u03bc_max * (\u03bb - t) / A + 2))` | \u03bb | threshold/<br>tangent | n.a. | \u03bc_max | K | entire curve |\n",
    "| Gompertz (phenom) | parametric | `ln(N(t)/N0) = A * exp(-exp(\u03bc_max * exp(1) * (\u03bb - t) / A + 1))` | \u03bb | threshold/<br>tangent | n.a. | \u03bc_max | K | entire curve |\n",
    "| Gompertz (modified) | parametric | `ln(N(t)/N0) = A * exp(-exp(\u03bc_max * exp(1) * (\u03bb - t) / A + 1)) + A * exp(\u03b1 * (t - t_shift))` | \u03bb | threshold/<br>tangent | n.a. | \u03bc_max | K | entire curve |\n",
    "| Richards (phenom) | parametric | `ln(N(t)/N0) = A * (1 + \u03bd * exp(1 + \u03bd + \u03bc_max * (1 + \u03bd)**(1/\u03bd) * (\u03bb - t) / A))**(-1/\u03bd)` | \u03bb | threshold/<br>tangent | n.a. | \u03bc_max | K | entire curve |\n",
    "\n",
    "### Understanding Growth Rates: Intrinsic vs. Observed\n",
    "\n",
    "**Important distinction:**\n",
    "\n",
    "- **`mu_max`** (\u03bc_max): The **observed** maximum specific growth rate calculated from the fitted curve as max(d(ln N)/dt). This is what you measure from the data.\n",
    "\n",
    "- **`intrinsic_growth_rate`**: The **model parameter** representing intrinsic growth capacity:\n",
    "  - **Parametric models**: This is a fitted parameter (e.g., `r` in Logistic, `mu_max` in Gompertz)\n",
    "  - **Non-parametric methods**: Returns `None` (no model parameter exists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mechanistic Models\n",
    "\n",
    "Mechanistic models are ODE-based parametric models that encode growth dynamics as differential equations.\n",
    "\n",
    "### Fit Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit mechanistic models\n",
    "fit_mech_logistic = gc.parametric.fit_parametric(t, N, method=\"mech_logistic\")\n",
    "fit_mech_gompertz = gc.parametric.fit_parametric(t, N, method=\"mech_gompertz\")\n",
    "fit_mech_richards = gc.parametric.fit_parametric(t, N, method=\"mech_richards\")\n",
    "fit_mech_baranyi = gc.parametric.fit_parametric(t, N, method=\"mech_baranyi\")\n",
    "\n",
    "# Combine fits into a dictionary\n",
    "mechanistic_fits = {\n",
    "    \"mech_logistic\": fit_mech_logistic,\n",
    "    \"mech_gompertz\": fit_mech_gompertz,\n",
    "    \"mech_richards\": fit_mech_richards,\n",
    "    \"mech_baranyi\": fit_mech_baranyi,\n",
    "}\n",
    "\n",
    "# Display example fit result\n",
    "print(\"=== Logistic Fit Result ===\")\n",
    "pprint(fit_mech_logistic, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Growth Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract stats from each mechanistic fit\n",
    "stats_mech_logistic = gc.inference.extract_stats(fit_mech_logistic, t, N)\n",
    "stats_mech_gompertz = gc.inference.extract_stats(fit_mech_gompertz, t, N)\n",
    "stats_mech_richards = gc.inference.extract_stats(fit_mech_richards, t, N)\n",
    "stats_mech_baranyi = gc.inference.extract_stats(fit_mech_baranyi, t, N)\n",
    "\n",
    "# Combine stats into a dictionary\n",
    "mechanistic_stats = {\n",
    "    \"mech_logistic\": stats_mech_logistic,\n",
    "    \"mech_gompertz\": stats_mech_gompertz,\n",
    "    \"mech_richards\": stats_mech_richards,\n",
    "    \"mech_baranyi\": stats_mech_baranyi,\n",
    "}\n",
    "\n",
    "# Display growth statistics for logistic fit\n",
    "print(\"=== Logistic Growth Statistics ===\")\n",
    "pprint(stats_mech_logistic, indent=2)\n",
    "\n",
    "# Create comparison dataframe\n",
    "print(\"\\n=== Mechanistic Models Comparison ===\")\n",
    "mechanistic_df = pd.DataFrame(mechanistic_stats).T[\n",
    "    [\n",
    "        \"mu_max\",\n",
    "        \"intrinsic_growth_rate\",\n",
    "        \"doubling_time\",\n",
    "        \"time_at_umax\",\n",
    "        \"exp_phase_start\",\n",
    "        \"exp_phase_end\",\n",
    "        \"model_rmse\",\n",
    "    ]\n",
    "]\n",
    "mechanistic_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phenomenological Models - Parametric\n",
    "\n",
    "These are phenomenological parametric models fit in ln-space.\n",
    "\n",
    "### Fit Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit phenomenological parametric models\n",
    "fit_phenom_logistic = gc.parametric.fit_parametric(t, N, method=\"phenom_logistic\")\n",
    "fit_phenom_gompertz = gc.parametric.fit_parametric(t, N, method=\"phenom_gompertz\")\n",
    "fit_phenom_gompertz_modified = gc.parametric.fit_parametric(\n",
    "    t, N, method=\"phenom_gompertz_modified\"\n",
    ")\n",
    "fit_phenom_richards = gc.parametric.fit_parametric(t, N, method=\"phenom_richards\")\n",
    "\n",
    "# Combine fits into a dictionary\n",
    "phenom_param_fits = {\n",
    "    \"phenom_logistic\": fit_phenom_logistic,\n",
    "    \"phenom_gompertz\": fit_phenom_gompertz,\n",
    "    \"phenom_gompertz_modified\": fit_phenom_gompertz_modified,\n",
    "    \"phenom_richards\": fit_phenom_richards,\n",
    "}\n",
    "\n",
    "# Display example fit\n",
    "print(\"=== Phenomenological Logistic Fit ===\")\n",
    "pprint(fit_phenom_logistic, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Growth Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract stats from each phenomenological parametric fit\n",
    "stats_phenom_logistic = gc.inference.extract_stats(\n",
    "    fit_phenom_logistic, t, N, phase_boundary_method=\"tangent\"\n",
    ")\n",
    "stats_phenom_gompertz = gc.inference.extract_stats(\n",
    "    fit_phenom_gompertz, t, N, phase_boundary_method=\"tangent\"\n",
    ")\n",
    "stats_phenom_gompertz_modified = gc.inference.extract_stats(\n",
    "    fit_phenom_gompertz_modified, t, N, phase_boundary_method=\"tangent\"\n",
    ")\n",
    "stats_phenom_richards = gc.inference.extract_stats(\n",
    "    fit_phenom_richards, t, N, phase_boundary_method=\"tangent\"\n",
    ")\n",
    "\n",
    "# Combine stats into a dictionary\n",
    "phenom_param_stats = {\n",
    "    \"phenom_logistic\": stats_phenom_logistic,\n",
    "    \"phenom_gompertz\": stats_phenom_gompertz,\n",
    "    \"phenom_gompertz_modified\": stats_phenom_gompertz_modified,\n",
    "    \"phenom_richards\": stats_phenom_richards,\n",
    "}\n",
    "\n",
    "# Display example stats\n",
    "print(\"=== Phenomenological Logistic Stats ===\")\n",
    "pprint(stats_phenom_logistic, indent=2)\n",
    "\n",
    "# Create comparison dataframe\n",
    "print(\"\\n=== Phenomenological Parametric Models Comparison ===\")\n",
    "phenom_param_df = pd.DataFrame(phenom_param_stats).T[\n",
    "    [\n",
    "        \"mu_max\",\n",
    "        \"intrinsic_growth_rate\",\n",
    "        \"doubling_time\",\n",
    "        \"time_at_umax\",\n",
    "        \"exp_phase_start\",\n",
    "        \"exp_phase_end\",\n",
    "        \"model_rmse\",\n",
    "    ]\n",
    "]\n",
    "phenom_param_df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phenomenological Models - Non-Parametric\n",
    "\n",
    "These are phenomenological non-parametric fits that estimate growth features directly from local trends and smoothing.\n",
    "\n",
    "### Fit Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit non-parametric models\n",
    "fit_spline = gc.non_parametric.fit_non_parametric(\n",
    "    t,\n",
    "    N,\n",
    "    method=\"spline\",\n",
    "    spline_s=0.2,\n",
    ")\n",
    "\n",
    "fit_sliding_window = gc.non_parametric.fit_non_parametric(\n",
    "    t,\n",
    "    N,\n",
    "    method=\"sliding_window\",\n",
    "    window_points=7,\n",
    ")\n",
    "\n",
    "# Combine fits into a dictionary\n",
    "phenom_nonparam_fits = {\n",
    "    \"spline\": fit_spline,\n",
    "    \"sliding_window\": fit_sliding_window,\n",
    "}\n",
    "\n",
    "# Display non-parametric fit results\n",
    "pprint(phenom_nonparam_fits, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Growth Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract stats from each non-parametric fit\n",
    "stats_spline = gc.inference.extract_stats(\n",
    "    fit_spline,\n",
    "    t,\n",
    "    N,\n",
    "    phase_boundary_method=\"tangent\",\n",
    ")\n",
    "\n",
    "stats_sliding_window = gc.inference.extract_stats(\n",
    "    fit_sliding_window,\n",
    "    t,\n",
    "    N,\n",
    "    phase_boundary_method=\"tangent\",\n",
    ")\n",
    "\n",
    "# Combine stats into a dictionary\n",
    "phenom_nonparam_stats = {\n",
    "    \"spline\": stats_spline,\n",
    "    \"sliding_window\": stats_sliding_window,\n",
    "}\n",
    "\n",
    "# Create comparison dataframe\n",
    "print(\"=== Phenomenological Non-Parametric Models Comparison ===\")\n",
    "phenom_nonparam_df = pd.DataFrame(phenom_nonparam_stats).T[\n",
    "    [\n",
    "        \"mu_max\",\n",
    "        \"intrinsic_growth_rate\",\n",
    "        \"doubling_time\",\n",
    "        \"time_at_umax\",\n",
    "        \"exp_phase_start\",\n",
    "        \"exp_phase_end\",\n",
    "        \"model_rmse\",\n",
    "    ]\n",
    "]\n",
    "phenom_nonparam_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing Phase Boundary Detection\n",
    "\n",
    "Two methods are available for determining exponential phase boundaries:\n",
    "\n",
    "### 1. **Threshold Method**\n",
    "- Tracks the instantaneous specific growth rate \u03bc(t)\n",
    "- `exp_phase_start`: First time when \u03bc exceeds a fraction of \u03bc_max (default: 15%)\n",
    "- `exp_phase_end`: First time after peak when \u03bc drops below the threshold\n",
    "\n",
    "### 2. **Tangent Method**\n",
    "- Constructs a tangent line in log space at the point of maximum growth rate\n",
    "- Extends this tangent to intersect baseline (exp_phase_start) and plateau (exp_phase_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare phase-boundary methods on the same fit\n",
    "phase_boundary_rows = []\n",
    "\n",
    "# Tangent method\n",
    "stats_tangent = gc.inference.extract_stats(\n",
    "    fit_spline,\n",
    "    t,\n",
    "    N,\n",
    "    phase_boundary_method=\"tangent\",\n",
    ")\n",
    "phase_boundary_rows.append(\n",
    "    {\n",
    "        \"label\": \"tangent\",\n",
    "        \"method\": \"tangent\",\n",
    "        \"lag_frac\": np.nan,\n",
    "        \"exp_frac\": np.nan,\n",
    "        \"stats\": stats_tangent,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Threshold method at different cutoffs\n",
    "for frac, label in [(0.10, \"threshold_low\"), (0.30, \"threshold_high\")]:\n",
    "    stats_threshold = gc.inference.extract_stats(\n",
    "        fit_spline,\n",
    "        t,\n",
    "        N,\n",
    "        phase_boundary_method=\"threshold\",\n",
    "        lag_frac=frac,\n",
    "        exp_frac=frac,\n",
    "    )\n",
    "    phase_boundary_rows.append(\n",
    "        {\n",
    "            \"label\": label,\n",
    "            \"method\": \"threshold\",\n",
    "            \"lag_frac\": frac,\n",
    "            \"exp_frac\": frac,\n",
    "            \"stats\": stats_threshold,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Create comparison dataframe\n",
    "print(\"=== Phase Boundary Method Comparison ===\")\n",
    "phase_boundary_df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"label\": row[\"label\"],\n",
    "            \"method\": row[\"method\"],\n",
    "            \"lag_frac\": row[\"lag_frac\"],\n",
    "            \"exp_frac\": row[\"exp_frac\"],\n",
    "            \"exp_phase_start\": row[\"stats\"][\"exp_phase_start\"],\n",
    "            \"exp_phase_end\": row[\"stats\"][\"exp_phase_end\"],\n",
    "        }\n",
    "        for row in phase_boundary_rows\n",
    "    ]\n",
    ")\n",
    "phase_boundary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6430ce6",
   "metadata": {},
   "source": [
    "See more details on the phase boundary methods in the next tutorial notebook:\n",
    "[`plotting.ipynb`](plotting.ipynb) (Visualize fitted growth curves, derivatives,\n",
    "and growth statistics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
