{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1pioanl0d5x",
   "metadata": {},
   "source": [
    "> **Prerequisites:** run `outlier_test_dataset.ipynb` first to generate `test_traces.csv` and `test_labels.csv` in the same directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1p4xx6d1s5k",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdcvcuiswc",
   "metadata": {},
   "source": [
    "# Outlier Detection — Method Comparison\n",
    "\n",
    "Evaluates lightweight outlier detection methods against the labelled test set produced by `outlier_test_dataset.ipynb`.  \n",
    "Primary metric: **F1 score** on the outlier class.\n",
    "\n",
    "| Method | Principle |\n",
    "|---|---|\n",
    "| **z-score Δod** | Robust z-score on first differences |\n",
    "| **IQR Δod** | Tukey IQR fence on first differences |\n",
    "| **Hampel** | Sliding-window median/MAD identifier |\n",
    "| **spline residuals** | Smooth spline fit → residual MAD z-score |\n",
    "| **isolation forest** | Anomaly score from random partitioning tree |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ttfkjz3x39",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_df = pd.read_csv(\"generated_data/test_traces.csv\")\n",
    "labels_df = pd.read_csv(\"generated_data/test_labels.csv\")\n",
    "gt = labels_df[\"is_outlier\"].astype(bool)\n",
    "\n",
    "n_out = int(gt.sum())\n",
    "print(\n",
    "    f\"Loaded  {len(traces_df):,} points · \"\n",
    "    f\"{traces_df['curve_id'].nunique()} curves · \"\n",
    "    f\"{n_out} ground-truth outliers ({100 * n_out / len(traces_df):.2f}%)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xj8abfay6p",
   "metadata": {},
   "outputs": [],
   "source": "# pip install pyod   ← needed for ECOD, COPOD, LOF\n# growthcurves package must be installed: pip install -e ../\n\n\ndef _mad_z(x: np.ndarray) -> np.ndarray:\n    med = np.median(x)\n    mad = np.median(np.abs(x - med))\n    return np.zeros(len(x)) if mad < 1e-12 else np.abs(x - med) / (1.4826 * mad)\n\n\ndef _fold_flag(scores: np.ndarray, k: float, noise_pct: float = 50) -> np.ndarray:\n    \"\"\"Flag points where score > k × noise_floor (= percentile(scores, noise_pct)).\"\"\"\n    noise = np.percentile(scores, noise_pct)\n    if noise < 1e-12:\n        return np.zeros(len(scores), dtype=bool)\n    return (scores / noise) > k\n\n\ndef _mad_flag(scores: np.ndarray, k: float) -> np.ndarray:\n    \"\"\"Flag points with MAD z-score > k.\"\"\"\n    return _mad_z(scores) > k\n\n\ndef m_zscore_diff(t, od, k=8.0):\n    return _fold_flag(np.abs(np.diff(od, prepend=od[0])), k)\n\ndef m_iqr_diff(t, od, k=8.0):\n    d = np.diff(od, prepend=od[0])\n    return _fold_flag(np.abs(d - np.median(d)), k)\n\ndef m_hampel(t, od, window=15, k=3.0):\n    \"\"\"Hampel identifier via growthcurves.preprocessing.detect_outliers.\"\"\"\n    from growthcurves.preprocessing import detect_outliers\n    return detect_outliers(od, method=\"hampel\", window=window, factor=k)\n\ndef m_spline_residuals(t, od, k=3.5):\n    \"\"\"Spline residuals with MAD z-score threshold (residuals are approx Gaussian).\"\"\"\n    from growthcurves.non_parametric import fit_spline\n    from growthcurves.models import spline_from_params\n    result = fit_spline(t, od, smooth=\"fast\")\n    if result is None:\n        return np.zeros(len(t), dtype=bool)\n    spl = spline_from_params(result[\"params\"])\n    raw = np.abs(od - np.exp(spl(t)))\n    return _mad_flag(raw, k)\n\ndef m_isolation_forest(t, od, k=10.0):\n    from sklearn.ensemble import IsolationForest\n    d = np.diff(od, prepend=od[0])\n    X = np.column_stack([od, d])\n    clf = IsolationForest(n_estimators=200, contamination=\"auto\", random_state=42)\n    clf.fit(X)\n    raw = -clf.score_samples(X)\n    raw = raw - raw.min()\n    return _fold_flag(raw, k)\n\ndef m_ecod(t, od, k=3.5):\n    \"\"\"ECOD outlier detection via growthcurves.preprocessing.detect_outliers.\"\"\"\n    from growthcurves.preprocessing import detect_outliers\n    return detect_outliers(od, method=\"ecod\", factor=k)\n\ndef m_copod(t, od, k=3.5, window=15):\n    \"\"\"COPOD using local rolling-mean residual + od + Δod.\"\"\"\n    from pyod.models.copod import COPOD\n    n, half = len(od), window // 2\n    residual = np.zeros(n)\n    for i in range(n):\n        win = od[max(0, i - half): min(n, i + half + 1)]\n        residual[i] = od[i] - win.mean()\n    d = np.diff(od, prepend=od[0])\n    X = np.column_stack([np.abs(residual), od, d])\n    clf = COPOD(); clf.fit(X)\n    return _mad_flag(clf.decision_scores_, k)\n\ndef m_lof(t, od, k=3.5):\n    from pyod.models.lof import LOF\n    d = np.diff(od, prepend=od[0])\n    X = np.column_stack([od, d])\n    clf = LOF(); clf.fit(X)\n    return _mad_flag(clf.decision_scores_, k)\n\ndef m_growthcurves(t, od, window_size=15, factor=1.5):\n    \"\"\"Sliding-window IQR outlier detection via\n    growthcurves.preprocessing.detect_outliers.\"\"\"\n    from growthcurves.preprocessing import detect_outliers\n    return detect_outliers(od, method=\"iqr\", window_size=window_size, factor=factor)\n\n\nMETHODS = {\n    \"z-score Δod\":      m_zscore_diff,\n    \"IQR Δod\":          m_iqr_diff,\n    \"Hampel\":           m_hampel,\n    \"spline residuals\": m_spline_residuals,\n    \"isolation forest\": m_isolation_forest,\n    \"ECOD\":             m_ecod,\n    \"COPOD\":            m_copod,\n    \"LOF\":              m_lof,\n    \"growthcurves\":     m_growthcurves,\n}\n\nMETHOD_COLORS = [\n    \"#3B82F6\",  # z-score Δod    — blue\n    \"#F97316\",  # IQR Δod        — orange\n    \"#10B981\",  # Hampel          — green\n    \"#8B5CF6\",  # spline res.     — purple\n    \"#EF4444\",  # isolation f.    — red\n    \"#06B6D4\",  # ECOD            — cyan\n    \"#84CC16\",  # COPOD           — lime\n    \"#F59E0B\",  # LOF             — amber\n    \"#0D9488\",  # growthcurves    — teal\n]\ncolor_map = dict(zip(METHODS, METHOD_COLORS))\n\nprint(\"Methods:\", list(METHODS))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ktf1dt44aej",
   "metadata": {},
   "outputs": [],
   "source": "predictions: dict = {}\n\nfor name, fn in METHODS.items():\n    parts = []\n    for _cid, grp in traces_df.groupby(\"curve_id\", sort=False):\n        t  = grp[\"t\"].to_numpy()\n        od = grp[\"od\"].to_numpy()\n        parts.append(pd.Series(fn(t, od).astype(bool), index=grp.index))\n    predictions[name] = pd.concat(parts)\n\nprint(f\"{'Method':25s}  {'Flagged':>7}  {'GT outliers':>11}\")\nfor name, pred in predictions.items():\n    print(f\"  {name:23s}  {int(pred.sum()):>7}  {int(gt.sum()):>11}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b32rdoko047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "rows = []\n",
    "for name, pred in predictions.items():\n",
    "    p, g = pred.astype(int), gt.astype(int)\n",
    "    rows.append(\n",
    "        {\n",
    "            \"method\": name,\n",
    "            \"F1\": round(f1_score(g, p, zero_division=0), 3),\n",
    "            \"precision\": round(precision_score(g, p, zero_division=0), 3),\n",
    "            \"recall\": round(recall_score(g, p, zero_division=0), 3),\n",
    "            \"flagged\": int(p.sum()),\n",
    "        }\n",
    "    )\n",
    "\n",
    "metrics_df = (\n",
    "    pd.DataFrame(rows).sort_values(\"F1\", ascending=False).reset_index(drop=True)\n",
    ")\n",
    "display(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mb5948ad4k",
   "metadata": {},
   "outputs": [],
   "source": "import time\n\nN_REPS = 5   # repeat each measurement to reduce noise\n\ntiming_rows = []\nfor _ in range(N_REPS):\n    for name, fn in METHODS.items():\n        for _cid, grp in traces_df.groupby(\"curve_id\", sort=False):\n            t  = grp[\"t\"].to_numpy()\n            od = grp[\"od\"].to_numpy()\n            t0 = time.perf_counter()\n            fn(t, od)\n            timing_rows.append({\"method\": name, \"ms\": (time.perf_counter() - t0) * 1e3})\n\ntiming_df = pd.DataFrame(timing_rows)\nspeed = (\n    timing_df.groupby(\"method\")[\"ms\"]\n    .agg(median_ms=\"median\", std_ms=\"std\")\n    .reset_index()\n    .sort_values(\"median_ms\")\n)\n\nn_curves = traces_df[\"curve_id\"].nunique()\nfig = go.Figure(go.Bar(\n    x=speed[\"median_ms\"],\n    y=speed[\"method\"],\n    orientation=\"h\",\n    error_x=dict(type=\"data\", array=speed[\"std_ms\"].tolist(), visible=True),\n    marker_color=[color_map[m] for m in speed[\"method\"]],\n    text=[f\"{v:.2f} ms\" for v in speed[\"median_ms\"]],\n    textposition=\"outside\",\n))\nfig.update_layout(\n    template=\"plotly_white\",\n    height=50 + len(METHODS) * 45,\n    width=640,\n    title=f\"Runtime per curve — median ± std  ({N_REPS} reps × {n_curves} curves)\",\n    xaxis=dict(title=\"ms\", type=\"log\"),\n    yaxis_title=\"\",\n    margin=dict(t=50, b=40, l=140, r=90),\n)\nfig.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ru2h8lu78qk",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_names = list(METHODS.keys())\n",
    "ordered_names = metrics_df[\"method\"].tolist()\n",
    "\n",
    "# ── Bar charts: F1 / Precision / Recall ──────────────────────────────────────\n",
    "fig_bars = make_subplots(\n",
    "    rows=1,\n",
    "    cols=3,\n",
    "    subplot_titles=[\"F1 score\", \"Precision\", \"Recall\"],\n",
    "    horizontal_spacing=0.10,\n",
    ")\n",
    "for col, metric in enumerate([\"F1\", \"precision\", \"recall\"], start=1):\n",
    "    vals = metrics_df.set_index(\"method\").loc[ordered_names, metric].tolist()\n",
    "    fig_bars.add_trace(\n",
    "        go.Bar(\n",
    "            x=ordered_names,\n",
    "            y=vals,\n",
    "            marker_color=[color_map[m] for m in ordered_names],\n",
    "            showlegend=False,\n",
    "            text=[f\"{v:.2f}\" for v in vals],\n",
    "            textposition=\"outside\",\n",
    "        ),\n",
    "        row=1,\n",
    "        col=col,\n",
    "    )\n",
    "    fig_bars.update_yaxes(range=[0, 1.18], row=1, col=col)\n",
    "fig_bars.update_layout(\n",
    "    template=\"plotly_white\",\n",
    "    height=380,\n",
    "    width=1100,\n",
    "    title=\"Method comparison — ground truth test set\",\n",
    ")\n",
    "fig_bars.show()\n",
    "\n",
    "# ── Per-curve F1 heatmap ──────────────────────────────────────────────────────\n",
    "curve_ids = traces_df[\"curve_id\"].unique()\n",
    "z = np.full((len(curve_ids), len(method_names)), np.nan)\n",
    "for j, mname in enumerate(method_names):\n",
    "    pred = predictions[mname]\n",
    "    for i, cid in enumerate(curve_ids):\n",
    "        idx = traces_df[traces_df[\"curve_id\"] == cid].index\n",
    "        z[i, j] = f1_score(\n",
    "            gt.loc[idx].astype(int), pred.loc[idx].astype(int), zero_division=0\n",
    "        )\n",
    "\n",
    "fig_heat = go.Figure(\n",
    "    go.Heatmap(\n",
    "        z=z,\n",
    "        x=method_names,\n",
    "        y=list(curve_ids),\n",
    "        colorscale=\"RdYlGn\",\n",
    "        zmin=0,\n",
    "        zmax=1,\n",
    "        text=np.round(z, 2).astype(str),\n",
    "        texttemplate=\"%{text}\",\n",
    "        colorbar=dict(title=\"F1\"),\n",
    "        hovertemplate=\"curve: %{y}<br>method: %{x}<br>F1: %{z:.3f}<extra></extra>\",\n",
    "    )\n",
    ")\n",
    "fig_heat.update_layout(\n",
    "    template=\"plotly_white\",\n",
    "    height=360,\n",
    "    width=1100,\n",
    "    title=\"Per-curve F1 score by method\",\n",
    "    xaxis_title=\"Method\",\n",
    "    yaxis_title=\"Curve\",\n",
    "    xaxis=dict(tickangle=-35),\n",
    "    margin=dict(b=110),\n",
    ")\n",
    "fig_heat.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrlpj0500s",
   "metadata": {},
   "source": [
    "### 7 · Per-curve visual inspection\n",
    "\n",
    "For each curve: the OD trace with **○ ground-truth markers** on top, then one labelled strip per method below (shared x-axis).\n",
    "\n",
    "- **○ open circle** in a strip = this time point is in the ground truth  \n",
    "- **■ filled square** = flagged by the method  \n",
    "- Both at the same position = true positive; circle only = false negative; square only = false positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wz4kp0szk5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_methods = len(method_names)\n",
    "row_heights = [5] + [1] * n_methods  # data trace tall, flag strips short\n",
    "\n",
    "for cid in traces_df[\"curve_id\"].unique():\n",
    "    grp = traces_df[traces_df[\"curve_id\"] == cid]\n",
    "    t = grp[\"t\"].to_numpy()\n",
    "    od = grp[\"od\"].to_numpy()\n",
    "    gt_c = gt.loc[grp.index].to_numpy()\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=1 + n_methods,\n",
    "        cols=1,\n",
    "        shared_xaxes=True,\n",
    "        row_heights=row_heights,\n",
    "        vertical_spacing=0.02,\n",
    "    )\n",
    "\n",
    "    # ── Row 1: OD trace + ground-truth markers ────────────────────────────────\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=t,\n",
    "            y=od,\n",
    "            mode=\"lines+markers\",\n",
    "            line=dict(color=\"#CBD5E1\", width=1),\n",
    "            marker=dict(size=4, color=\"#94A3B8\"),\n",
    "            showlegend=False,\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "    if gt_c.any():\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=t[gt_c],\n",
    "                y=od[gt_c],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(\n",
    "                    size=16, symbol=\"circle-open\", color=\"black\", line=dict(width=2.5)\n",
    "                ),\n",
    "                showlegend=False,\n",
    "                hovertemplate=\"GT outlier<br>t=%{x:.0f}  OD=%{y:.4f}<extra></extra>\",\n",
    "            ),\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "    # ── Rows 2+: one strip per method ─────────────────────────────────────────\n",
    "    for j, mname in enumerate(method_names):\n",
    "        row = j + 2\n",
    "        p_c = predictions[mname].loc[grp.index].to_numpy()\n",
    "\n",
    "        # Mark GT positions in every strip (open circles) so alignment is clear\n",
    "        if gt_c.any():\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=t[gt_c],\n",
    "                    y=np.ones(gt_c.sum()),\n",
    "                    mode=\"markers\",\n",
    "                    marker=dict(\n",
    "                        size=12, symbol=\"circle-open\", color=\"black\", line=dict(width=2)\n",
    "                    ),\n",
    "                    showlegend=False,\n",
    "                    hoverinfo=\"skip\",\n",
    "                ),\n",
    "                row=row,\n",
    "                col=1,\n",
    "            )\n",
    "\n",
    "        # Filled squares where this method fires\n",
    "        if p_c.any():\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=t[p_c],\n",
    "                    y=np.ones(p_c.sum()),\n",
    "                    mode=\"markers\",\n",
    "                    marker=dict(\n",
    "                        size=10, symbol=\"square\", color=color_map[mname], opacity=0.9\n",
    "                    ),\n",
    "                    showlegend=False,\n",
    "                    hovertemplate=f\"{mname}<br>t=%{{x:.0f}}<extra></extra>\",\n",
    "                ),\n",
    "                row=row,\n",
    "                col=1,\n",
    "            )\n",
    "\n",
    "        fig.update_yaxes(\n",
    "            title_text=mname,\n",
    "            showticklabels=False,\n",
    "            range=[0, 2],\n",
    "            row=row,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "    fig.update_yaxes(title_text=\"OD\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Time\", row=1 + n_methods, col=1)\n",
    "    fig.update_layout(\n",
    "        title=f\"<b>{cid}</b>  —  ○ = ground truth  ■ = flagged by method\",\n",
    "        template=\"plotly_white\",\n",
    "        height=300 + n_methods * 50,\n",
    "        width=950,\n",
    "        showlegend=False,\n",
    "        margin=dict(t=45, b=35, l=140, r=15),\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9z3pdbey73",
   "metadata": {},
   "source": [
    "### 8 · Anomaly scores per method\n",
    "\n",
    "Each method row shows the raw anomaly score (MAD z-score units) across time.  \n",
    "**Red dashed line** = threshold (3.5). **○** = ground truth outlier position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kqaxkwiku6t",
   "metadata": {},
   "outputs": [],
   "source": "# Threshold k and type per method\n# \"fold\"  → thresh = k × median(scores)         (sparse/heavy-tailed)\n# \"mad\"   → thresh = median + k × 1.4826 × MAD  (shift-distributed, approx Gaussian)\n# \"fixed\" → thresh = k                           (scores already in interpretable units)\nTHRESH = {\n    \"z-score Δod\":      (\"fold\",  8.0),\n    \"IQR Δod\":          (\"fold\",  8.0),\n    \"Hampel\":           (\"fixed\", 3.0),  # scores are per-window MAD z-scores\n    \"spline residuals\": (\"mad\",   3.5),  # residuals are approx Gaussian\n    \"isolation forest\": (\"fold\",  10.0),\n    \"ECOD\":             (\"mad\",   3.5),\n    \"COPOD\":            (\"mad\",   3.5),\n    \"LOF\":              (\"mad\",   3.5),\n    \"growthcurves\":     (\"fixed\", 1.5),\n}\nNOISE_PCT = 50\n\n\ndef _hex_to_rgba(hex_color, alpha=0.12):\n    h = hex_color.lstrip(\"#\")\n    r, g, b = int(h[0:2], 16), int(h[2:4], 16), int(h[4:6], 16)\n    return f\"rgba({r},{g},{b},{alpha})\"\n\n\ndef _thresh_value(scores, thresh_type, k):\n    if thresh_type == \"fold\":\n        noise = np.percentile(scores, NOISE_PCT)\n        return k * noise\n    elif thresh_type == \"fixed\":\n        return k\n    else:  # \"mad\"\n        med = np.median(scores)\n        mad = np.median(np.abs(scores - med))\n        return med + k * 1.4826 * mad\n\n\ndef _sc_diff(t, od):\n    return np.abs(np.diff(od, prepend=od[0]))\n\ndef _sc_iqr_diff(t, od):\n    d = np.diff(od, prepend=od[0])\n    return np.abs(d - np.median(d))\n\ndef _sc_hampel(t, od, window=15):\n    \"\"\"Per-window MAD z-score — scores are directly comparable to the\n    fixed threshold.\"\"\"\n    n, half = len(od), window // 2\n    raw = np.zeros(n)\n    for i in range(n):\n        nb = od[max(0, i - half): min(n, i + half + 1)]\n        med = np.median(nb)\n        mad = np.median(np.abs(nb - med))\n        if mad > 1e-12:\n            raw[i] = abs(od[i] - med) / (1.4826 * mad)\n    return raw\n\ndef _sc_spline(t, od):\n    from growthcurves.non_parametric import fit_spline\n    from growthcurves.models import spline_from_params\n    result = fit_spline(t, od, smooth=\"fast\")\n    if result is None:\n        return np.zeros(len(t))\n    spl = spline_from_params(result[\"params\"])\n    return np.abs(od - np.exp(spl(t)))\n\ndef _sc_iforest(t, od):\n    from sklearn.ensemble import IsolationForest\n    d = np.diff(od, prepend=od[0])\n    X = np.column_stack([od, d])\n    clf = IsolationForest(n_estimators=200, contamination=\"auto\", random_state=42)\n    clf.fit(X)\n    raw = -clf.score_samples(X)\n    return raw - raw.min()\n\ndef _sc_ecod(t, od, window=15):\n    \"\"\"ECOD score using local rolling-mean residual + od + Δod.\"\"\"\n    from pyod.models.ecod import ECOD\n    n, half = len(od), window // 2\n    residual = np.zeros(n)\n    for i in range(n):\n        win = od[max(0, i - half): min(n, i + half + 1)]\n        residual[i] = od[i] - win.mean()\n    d = np.diff(od, prepend=od[0])\n    X = np.column_stack([np.abs(residual), od, d])\n    clf = ECOD(); clf.fit(X)\n    return clf.decision_scores_\n\ndef _sc_copod(t, od, window=15):\n    \"\"\"COPOD score using local rolling-mean residual + od + Δod.\"\"\"\n    from pyod.models.copod import COPOD\n    n, half = len(od), window // 2\n    residual = np.zeros(n)\n    for i in range(n):\n        win = od[max(0, i - half): min(n, i + half + 1)]\n        residual[i] = od[i] - win.mean()\n    d = np.diff(od, prepend=od[0])\n    X = np.column_stack([np.abs(residual), od, d])\n    clf = COPOD(); clf.fit(X)\n    return clf.decision_scores_\n\ndef _sc_lof(t, od):\n    from pyod.models.lof import LOF\n    d = np.diff(od, prepend=od[0])\n    X = np.column_stack([od, d])\n    clf = LOF(); clf.fit(X)\n    return clf.decision_scores_\n\ndef _sc_growthcurves(t, od, window_size=15):\n    \"\"\"Distance beyond the IQR fence, in IQR units (0 for inliers).\"\"\"\n    n = len(od)\n    half = window_size // 2\n    raw = np.zeros(n)\n    for i in range(n):\n        win = od[max(0, i - half): min(n, i + half + 1)]\n        q1 = np.nanquantile(win, 0.25)\n        q3 = np.nanquantile(win, 0.75)\n        iqr = q3 - q1\n        if iqr > 1e-12:\n            raw[i] = max(od[i] - q3, q1 - od[i], 0.0) / iqr\n    return raw\n\nSCORERS = {\n    \"z-score Δod\":      _sc_diff,\n    \"IQR Δod\":          _sc_iqr_diff,\n    \"Hampel\":           _sc_hampel,\n    \"spline residuals\": _sc_spline,\n    \"isolation forest\": _sc_iforest,\n    \"ECOD\":             _sc_ecod,\n    \"COPOD\":            _sc_copod,\n    \"LOF\":              _sc_lof,\n    \"growthcurves\":     _sc_growthcurves,\n}\n\n# ── Plot ─────────────────────────────────────────────────────────────────────\nn_sc        = len(SCORERS)\nrow_heights = [3] + [2] * n_sc\n\nfor cid in traces_df[\"curve_id\"].unique():\n    grp  = traces_df[traces_df[\"curve_id\"] == cid]\n    t    = grp[\"t\"].to_numpy()\n    od   = grp[\"od\"].to_numpy()\n    gt_c = gt.loc[grp.index].to_numpy()\n\n    fig = make_subplots(\n        rows=1 + n_sc, cols=1,\n        shared_xaxes=True,\n        row_heights=row_heights,\n        vertical_spacing=0.02,\n    )\n\n    fig.add_trace(go.Scatter(\n        x=t, y=od, mode=\"lines+markers\",\n        line=dict(color=\"#CBD5E1\", width=1),\n        marker=dict(size=4, color=\"#94A3B8\"),\n        showlegend=False,\n    ), row=1, col=1)\n    if gt_c.any():\n        fig.add_trace(go.Scatter(\n            x=t[gt_c], y=od[gt_c], mode=\"markers\",\n            marker=dict(size=16, symbol=\"circle-open\", color=\"black\", line=dict(width=2.5)),\n            showlegend=False,\n        ), row=1, col=1)\n\n    for j, (mname, scorer) in enumerate(SCORERS.items()):\n        row    = j + 2\n        scores = scorer(t, od)\n        color  = color_map[mname]\n        t_type, k = THRESH[mname]\n        thresh = _thresh_value(scores, t_type, k)\n\n        fig.add_trace(go.Scatter(\n            x=t, y=scores, mode=\"lines\",\n            line=dict(color=color, width=1.5),\n            fill=\"tozeroy\", fillcolor=_hex_to_rgba(color),\n            showlegend=False,\n            hovertemplate=f\"{mname}  t=%{{x:.0f}}  score=%{{y:.3g}}\"\n                          f\"  (thresh={thresh:.3g})<extra></extra>\",\n        ), row=row, col=1)\n\n        fig.add_hline(y=thresh, line=dict(color=\"red\", width=1, dash=\"dot\"),\n                      row=row, col=1)\n\n        if gt_c.any():\n            fig.add_trace(go.Scatter(\n                x=t[gt_c], y=scores[gt_c], mode=\"markers\",\n                marker=dict(size=10, symbol=\"circle-open\", color=\"black\", line=dict(width=2)),\n                showlegend=False, hoverinfo=\"skip\",\n            ), row=row, col=1)\n\n        type_label = {\"fold\": \"fold\", \"mad\": \"MAD z\", \"fixed\": \"fixed\"}[t_type]\n        fig.update_yaxes(title_text=f\"{mname} ({type_label})\", row=row, col=1,\n                         title_standoff=4, rangemode=\"tozero\")\n\n    fig.update_yaxes(title_text=\"OD\", row=1, col=1)\n    fig.update_xaxes(title_text=\"Time\", row=1 + n_sc, col=1)\n    fig.update_layout(\n        title=f\"<b>{cid}</b>  —  raw anomaly scores  \"\n              f\"(red dash = threshold  |  ○ = ground truth)\",\n        template=\"plotly_white\",\n        height=240 + n_sc * 90,\n        width=950,\n        showlegend=False,\n        margin=dict(t=45, b=35, l=170, r=15),\n    )\n    fig.show()"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "growthcurves_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}