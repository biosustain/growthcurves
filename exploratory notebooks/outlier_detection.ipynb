{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1pioanl0d5x",
   "metadata": {},
   "source": [
    "> **Prerequisites:** run `outlier_test_dataset.ipynb` first to generate `test_traces.csv` and `test_labels.csv` in the same directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1p4xx6d1s5k",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdcvcuiswc",
   "metadata": {},
   "source": [
    "# Outlier Detection — Method Comparison\n",
    "\n",
    "Evaluates lightweight outlier detection methods against the labelled test set produced by `outlier_test_dataset.ipynb`.  \n",
    "Primary metric: **F1 score** on the outlier class.\n",
    "\n",
    "| Method | Principle |\n",
    "|---|---|\n",
    "| **z-score Δod** | Robust z-score on first differences |\n",
    "| **IQR Δod** | Tukey IQR fence on first differences |\n",
    "| **Hampel** | Sliding-window median/MAD identifier |\n",
    "| **spline residuals** | Smooth spline fit → residual MAD z-score |\n",
    "| **isolation forest** | Anomaly score from random partitioning tree |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ttfkjz3x39",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_df = pd.read_csv(\"generated_data/test_traces.csv\")\n",
    "labels_df  = pd.read_csv(\"generated_data/test_labels.csv\")\n",
    "gt = labels_df[\"is_outlier\"].astype(bool)\n",
    "\n",
    "n_out = int(gt.sum())\n",
    "print(\n",
    "    f\"Loaded  {len(traces_df):,} points · \"\n",
    "    f\"{traces_df['curve_id'].nunique()} curves · \"\n",
    "    f\"{n_out} ground-truth outliers ({100 * n_out / len(traces_df):.2f}%)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xj8abfay6p",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyod   ← needed for ECOD, COPOD, LOF\n",
    "# growthcurves package must be installed: pip install -e ../\n",
    "\n",
    "\n",
    "def _mad_z(x: np.ndarray) -> np.ndarray:\n",
    "    med = np.median(x)\n",
    "    mad = np.median(np.abs(x - med))\n",
    "    return np.zeros(len(x)) if mad < 1e-12 else np.abs(x - med) / (1.4826 * mad)\n",
    "\n",
    "\n",
    "def _fold_flag(scores: np.ndarray, k: float, noise_pct: float = 50) -> np.ndarray:\n",
    "    \"\"\"Flag points where score > k × noise_floor (= percentile(scores, noise_pct)).\"\"\"\n",
    "    noise = np.percentile(scores, noise_pct)\n",
    "    if noise < 1e-12:\n",
    "        return np.zeros(len(scores), dtype=bool)\n",
    "    return (scores / noise) > k\n",
    "\n",
    "\n",
    "def _mad_flag(scores: np.ndarray, k: float) -> np.ndarray:\n",
    "    \"\"\"Flag points with MAD z-score > k.\"\"\"\n",
    "    return _mad_z(scores) > k\n",
    "\n",
    "\n",
    "def m_zscore_diff(t, od, k=8.0):\n",
    "    return _fold_flag(np.abs(np.diff(od, prepend=od[0])), k)\n",
    "\n",
    "def m_iqr_diff(t, od, k=8.0):\n",
    "    d = np.diff(od, prepend=od[0])\n",
    "    return _fold_flag(np.abs(d - np.median(d)), k)\n",
    "\n",
    "def m_hampel(t, od, window=15, k=3.0):\n",
    "    \"\"\"Hampel identifier with per-window MAD z-score threshold (correct formulation).\"\"\"\n",
    "    n, half = len(od), window // 2\n",
    "    flags = np.zeros(n, dtype=bool)\n",
    "    for i in range(n):\n",
    "        nb = od[max(0, i - half): min(n, i + half + 1)]\n",
    "        med = np.median(nb)\n",
    "        mad = np.median(np.abs(nb - med))\n",
    "        if mad > 1e-12:\n",
    "            flags[i] = abs(od[i] - med) / (1.4826 * mad) > k\n",
    "    return flags\n",
    "\n",
    "def m_spline_residuals(t, od, k=3.5):\n",
    "    \"\"\"Spline residuals with MAD z-score threshold (residuals are approx Gaussian).\"\"\"\n",
    "    from growthcurves.non_parametric import fit_spline\n",
    "    from growthcurves.models import spline_from_params\n",
    "    result = fit_spline(t, od, smooth=\"fast\")\n",
    "    if result is None:\n",
    "        return np.zeros(len(t), dtype=bool)\n",
    "    spl = spline_from_params(result[\"params\"])\n",
    "    raw = np.abs(od - np.exp(spl(t)))\n",
    "    return _mad_flag(raw, k)\n",
    "\n",
    "def m_isolation_forest(t, od, k=10.0):\n",
    "    from sklearn.ensemble import IsolationForest\n",
    "    d = np.diff(od, prepend=od[0])\n",
    "    X = np.column_stack([od, d])\n",
    "    clf = IsolationForest(n_estimators=200, contamination=\"auto\", random_state=42)\n",
    "    clf.fit(X)\n",
    "    raw = -clf.score_samples(X)\n",
    "    raw = raw - raw.min()\n",
    "    return _fold_flag(raw, k)\n",
    "\n",
    "def m_ecod(t, od, k=3.5, window=15):\n",
    "    \"\"\"ECOD using local rolling-mean residual + od + Δod.\"\"\"\n",
    "    from pyod.models.ecod import ECOD\n",
    "    n, half = len(od), window // 2\n",
    "    residual = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        win = od[max(0, i - half): min(n, i + half + 1)]\n",
    "        residual[i] = od[i] - win.mean()\n",
    "    d = np.diff(od, prepend=od[0])\n",
    "    X = np.column_stack([np.abs(residual), od, d])\n",
    "    clf = ECOD(); clf.fit(X)\n",
    "    return _mad_flag(clf.decision_scores_, k)\n",
    "\n",
    "def m_copod(t, od, k=3.5, window=15):\n",
    "    \"\"\"COPOD using local rolling-mean residual + od + Δod.\"\"\"\n",
    "    from pyod.models.copod import COPOD\n",
    "    n, half = len(od), window // 2\n",
    "    residual = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        win = od[max(0, i - half): min(n, i + half + 1)]\n",
    "        residual[i] = od[i] - win.mean()\n",
    "    d = np.diff(od, prepend=od[0])\n",
    "    X = np.column_stack([np.abs(residual), od, d])\n",
    "    clf = COPOD(); clf.fit(X)\n",
    "    return _mad_flag(clf.decision_scores_, k)\n",
    "\n",
    "def m_lof(t, od, k=3.5):\n",
    "    from pyod.models.lof import LOF\n",
    "    d = np.diff(od, prepend=od[0])\n",
    "    X = np.column_stack([od, d])\n",
    "    clf = LOF(); clf.fit(X)\n",
    "    return _mad_flag(clf.decision_scores_, k)\n",
    "\n",
    "def m_growthcurves(t, od, window_size=15, factor=1.5):\n",
    "    \"\"\"Sliding-window IQR outlier detection from growthcurves.preprocessing.out_of_iqr.\"\"\"\n",
    "    from growthcurves.preprocessing import out_of_iqr\n",
    "    return out_of_iqr(od, window_size=window_size, factor=factor)\n",
    "\n",
    "\n",
    "METHODS = {\n",
    "    \"z-score Δod\":      m_zscore_diff,\n",
    "    \"IQR Δod\":          m_iqr_diff,\n",
    "    \"Hampel\":           m_hampel,\n",
    "    \"spline residuals\": m_spline_residuals,\n",
    "    \"isolation forest\": m_isolation_forest,\n",
    "    \"ECOD\":             m_ecod,\n",
    "    \"COPOD\":            m_copod,\n",
    "    \"LOF\":              m_lof,\n",
    "    \"growthcurves\":     m_growthcurves,\n",
    "}\n",
    "\n",
    "METHOD_COLORS = [\n",
    "    \"#3B82F6\",  # z-score Δod    — blue\n",
    "    \"#F97316\",  # IQR Δod        — orange\n",
    "    \"#10B981\",  # Hampel          — green\n",
    "    \"#8B5CF6\",  # spline res.     — purple\n",
    "    \"#EF4444\",  # isolation f.    — red\n",
    "    \"#06B6D4\",  # ECOD            — cyan\n",
    "    \"#84CC16\",  # COPOD           — lime\n",
    "    \"#F59E0B\",  # LOF             — amber\n",
    "    \"#0D9488\",  # growthcurves    — teal\n",
    "]\n",
    "color_map = dict(zip(METHODS, METHOD_COLORS))\n",
    "\n",
    "print(\"Methods:\", list(METHODS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ktf1dt44aej",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions: dict = {}\n",
    "\n",
    "for name, fn in METHODS.items():\n",
    "    parts = []\n",
    "    for cid, grp in traces_df.groupby(\"curve_id\", sort=False):\n",
    "        t  = grp[\"t\"].to_numpy()\n",
    "        od = grp[\"od\"].to_numpy()\n",
    "        parts.append(pd.Series(fn(t, od).astype(bool), index=grp.index))\n",
    "    predictions[name] = pd.concat(parts)\n",
    "\n",
    "print(f\"{'Method':25s}  {'Flagged':>7}  {'GT outliers':>11}\")\n",
    "for name, pred in predictions.items():\n",
    "    print(f\"  {name:23s}  {int(pred.sum()):>7}  {int(gt.sum()):>11}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b32rdoko047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "rows = []\n",
    "for name, pred in predictions.items():\n",
    "    p, g = pred.astype(int), gt.astype(int)\n",
    "    rows.append({\n",
    "        \"method\":    name,\n",
    "        \"F1\":        round(f1_score(g, p, zero_division=0), 3),\n",
    "        \"precision\": round(precision_score(g, p, zero_division=0), 3),\n",
    "        \"recall\":    round(recall_score(g, p, zero_division=0), 3),\n",
    "        \"flagged\":   int(p.sum()),\n",
    "    })\n",
    "\n",
    "metrics_df = (\n",
    "    pd.DataFrame(rows)\n",
    "    .sort_values(\"F1\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "display(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mb5948ad4k",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "N_REPS = 5   # repeat each measurement to reduce noise\n",
    "\n",
    "timing_rows = []\n",
    "for _ in range(N_REPS):\n",
    "    for name, fn in METHODS.items():\n",
    "        for cid, grp in traces_df.groupby(\"curve_id\", sort=False):\n",
    "            t  = grp[\"t\"].to_numpy()\n",
    "            od = grp[\"od\"].to_numpy()\n",
    "            t0 = time.perf_counter()\n",
    "            fn(t, od)\n",
    "            timing_rows.append({\"method\": name, \"ms\": (time.perf_counter() - t0) * 1e3})\n",
    "\n",
    "timing_df = pd.DataFrame(timing_rows)\n",
    "speed = (\n",
    "    timing_df.groupby(\"method\")[\"ms\"]\n",
    "    .agg(median_ms=\"median\", std_ms=\"std\")\n",
    "    .reset_index()\n",
    "    .sort_values(\"median_ms\")\n",
    ")\n",
    "\n",
    "fig = go.Figure(go.Bar(\n",
    "    x=speed[\"median_ms\"],\n",
    "    y=speed[\"method\"],\n",
    "    orientation=\"h\",\n",
    "    error_x=dict(type=\"data\", array=speed[\"std_ms\"].tolist(), visible=True),\n",
    "    marker_color=[color_map[m] for m in speed[\"method\"]],\n",
    "    text=[f\"{v:.2f} ms\" for v in speed[\"median_ms\"]],\n",
    "    textposition=\"outside\",\n",
    "))\n",
    "fig.update_layout(\n",
    "    template=\"plotly_white\",\n",
    "    height=50 + len(METHODS) * 45,\n",
    "    width=640,\n",
    "    title=f\"Runtime per curve — median ± std  ({N_REPS} reps × {traces_df['curve_id'].nunique()} curves)\",\n",
    "    xaxis=dict(title=\"ms\", type=\"log\"),\n",
    "    yaxis_title=\"\",\n",
    "    margin=dict(t=50, b=40, l=140, r=90),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ru2h8lu78qk",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_names  = list(METHODS.keys())\n",
    "ordered_names = metrics_df[\"method\"].tolist()\n",
    "\n",
    "# ── Bar charts: F1 / Precision / Recall ──────────────────────────────────────\n",
    "fig_bars = make_subplots(\n",
    "    rows=1, cols=3,\n",
    "    subplot_titles=[\"F1 score\", \"Precision\", \"Recall\"],\n",
    "    horizontal_spacing=0.10,\n",
    ")\n",
    "for col, metric in enumerate([\"F1\", \"precision\", \"recall\"], start=1):\n",
    "    vals = metrics_df.set_index(\"method\").loc[ordered_names, metric].tolist()\n",
    "    fig_bars.add_trace(\n",
    "        go.Bar(\n",
    "            x=ordered_names, y=vals,\n",
    "            marker_color=[color_map[m] for m in ordered_names],\n",
    "            showlegend=False,\n",
    "            text=[f\"{v:.2f}\" for v in vals], textposition=\"outside\",\n",
    "        ),\n",
    "        row=1, col=col,\n",
    "    )\n",
    "    fig_bars.update_yaxes(range=[0, 1.18], row=1, col=col)\n",
    "fig_bars.update_layout(\n",
    "    template=\"plotly_white\", height=380, width=1100,\n",
    "    title=\"Method comparison — ground truth test set\",\n",
    ")\n",
    "fig_bars.show()\n",
    "\n",
    "# ── Per-curve F1 heatmap ──────────────────────────────────────────────────────\n",
    "curve_ids = traces_df[\"curve_id\"].unique()\n",
    "z = np.full((len(curve_ids), len(method_names)), np.nan)\n",
    "for j, mname in enumerate(method_names):\n",
    "    pred = predictions[mname]\n",
    "    for i, cid in enumerate(curve_ids):\n",
    "        idx = traces_df[traces_df[\"curve_id\"] == cid].index\n",
    "        z[i, j] = f1_score(gt.loc[idx].astype(int), pred.loc[idx].astype(int), zero_division=0)\n",
    "\n",
    "fig_heat = go.Figure(go.Heatmap(\n",
    "    z=z, x=method_names, y=list(curve_ids),\n",
    "    colorscale=\"RdYlGn\", zmin=0, zmax=1,\n",
    "    text=np.round(z, 2).astype(str), texttemplate=\"%{text}\",\n",
    "    colorbar=dict(title=\"F1\"),\n",
    "    hovertemplate=\"curve: %{y}<br>method: %{x}<br>F1: %{z:.3f}<extra></extra>\",\n",
    "))\n",
    "fig_heat.update_layout(\n",
    "    template=\"plotly_white\", height=360, width=1100,\n",
    "    title=\"Per-curve F1 score by method\",\n",
    "    xaxis_title=\"Method\", yaxis_title=\"Curve\",\n",
    "    xaxis=dict(tickangle=-35),\n",
    "    margin=dict(b=110),\n",
    ")\n",
    "fig_heat.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrlpj0500s",
   "metadata": {},
   "source": [
    "### 7 · Per-curve visual inspection\n",
    "\n",
    "For each curve: the OD trace with **○ ground-truth markers** on top, then one labelled strip per method below (shared x-axis).\n",
    "\n",
    "- **○ open circle** in a strip = this time point is in the ground truth  \n",
    "- **■ filled square** = flagged by the method  \n",
    "- Both at the same position = true positive; circle only = false negative; square only = false positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wz4kp0szk5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_methods    = len(method_names)\n",
    "row_heights  = [5] + [1] * n_methods  # data trace tall, flag strips short\n",
    "\n",
    "for cid in traces_df[\"curve_id\"].unique():\n",
    "    grp  = traces_df[traces_df[\"curve_id\"] == cid]\n",
    "    t    = grp[\"t\"].to_numpy()\n",
    "    od   = grp[\"od\"].to_numpy()\n",
    "    gt_c = gt.loc[grp.index].to_numpy()\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=1 + n_methods,\n",
    "        cols=1,\n",
    "        shared_xaxes=True,\n",
    "        row_heights=row_heights,\n",
    "        vertical_spacing=0.02,\n",
    "    )\n",
    "\n",
    "    # ── Row 1: OD trace + ground-truth markers ────────────────────────────────\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=t, y=od, mode=\"lines+markers\",\n",
    "            line=dict(color=\"#CBD5E1\", width=1),\n",
    "            marker=dict(size=4, color=\"#94A3B8\"),\n",
    "            showlegend=False,\n",
    "        ),\n",
    "        row=1, col=1,\n",
    "    )\n",
    "    if gt_c.any():\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=t[gt_c], y=od[gt_c], mode=\"markers\",\n",
    "                marker=dict(size=16, symbol=\"circle-open\", color=\"black\",\n",
    "                            line=dict(width=2.5)),\n",
    "                showlegend=False,\n",
    "                hovertemplate=\"GT outlier<br>t=%{x:.0f}  OD=%{y:.4f}<extra></extra>\",\n",
    "            ),\n",
    "            row=1, col=1,\n",
    "        )\n",
    "\n",
    "    # ── Rows 2+: one strip per method ─────────────────────────────────────────\n",
    "    for j, mname in enumerate(method_names):\n",
    "        row = j + 2\n",
    "        p_c = predictions[mname].loc[grp.index].to_numpy()\n",
    "\n",
    "        # Mark GT positions in every strip (open circles) so alignment is clear\n",
    "        if gt_c.any():\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=t[gt_c], y=np.ones(gt_c.sum()),\n",
    "                    mode=\"markers\",\n",
    "                    marker=dict(size=12, symbol=\"circle-open\", color=\"black\",\n",
    "                                line=dict(width=2)),\n",
    "                    showlegend=False, hoverinfo=\"skip\",\n",
    "                ),\n",
    "                row=row, col=1,\n",
    "            )\n",
    "\n",
    "        # Filled squares where this method fires\n",
    "        if p_c.any():\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=t[p_c], y=np.ones(p_c.sum()),\n",
    "                    mode=\"markers\",\n",
    "                    marker=dict(size=10, symbol=\"square\",\n",
    "                                color=color_map[mname], opacity=0.9),\n",
    "                    showlegend=False,\n",
    "                    hovertemplate=f\"{mname}<br>t=%{{x:.0f}}<extra></extra>\",\n",
    "                ),\n",
    "                row=row, col=1,\n",
    "            )\n",
    "\n",
    "        fig.update_yaxes(\n",
    "            title_text=mname, showticklabels=False,\n",
    "            range=[0, 2], row=row, col=1,\n",
    "        )\n",
    "\n",
    "    fig.update_yaxes(title_text=\"OD\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Time\", row=1 + n_methods, col=1)\n",
    "    fig.update_layout(\n",
    "        title=f\"<b>{cid}</b>  —  ○ = ground truth  ■ = flagged by method\",\n",
    "        template=\"plotly_white\",\n",
    "        height=300 + n_methods * 50,\n",
    "        width=950,\n",
    "        showlegend=False,\n",
    "        margin=dict(t=45, b=35, l=140, r=15),\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9z3pdbey73",
   "metadata": {},
   "source": [
    "### 8 · Anomaly scores per method\n",
    "\n",
    "Each method row shows the raw anomaly score (MAD z-score units) across time.  \n",
    "**Red dashed line** = threshold (3.5). **○** = ground truth outlier position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kqaxkwiku6t",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold k and type per method\n",
    "# \"fold\"  → thresh = k × median(scores)         (sparse/heavy-tailed)\n",
    "# \"mad\"   → thresh = median + k × 1.4826 × MAD  (shift-distributed, approx Gaussian)\n",
    "# \"fixed\" → thresh = k                           (scores already in interpretable units)\n",
    "THRESH = {\n",
    "    \"z-score Δod\":      (\"fold\",  8.0),\n",
    "    \"IQR Δod\":          (\"fold\",  8.0),\n",
    "    \"Hampel\":           (\"fixed\", 3.0),  # scores are per-window MAD z-scores\n",
    "    \"spline residuals\": (\"mad\",   3.5),  # residuals are approx Gaussian\n",
    "    \"isolation forest\": (\"fold\",  10.0),\n",
    "    \"ECOD\":             (\"mad\",   3.5),\n",
    "    \"COPOD\":            (\"mad\",   3.5),\n",
    "    \"LOF\":              (\"mad\",   3.5),\n",
    "    \"growthcurves\":     (\"fixed\", 1.5),\n",
    "}\n",
    "NOISE_PCT = 50\n",
    "\n",
    "\n",
    "def _hex_to_rgba(hex_color, alpha=0.12):\n",
    "    h = hex_color.lstrip(\"#\")\n",
    "    r, g, b = int(h[0:2], 16), int(h[2:4], 16), int(h[4:6], 16)\n",
    "    return f\"rgba({r},{g},{b},{alpha})\"\n",
    "\n",
    "\n",
    "def _thresh_value(scores, thresh_type, k):\n",
    "    if thresh_type == \"fold\":\n",
    "        noise = np.percentile(scores, NOISE_PCT)\n",
    "        return k * noise\n",
    "    elif thresh_type == \"fixed\":\n",
    "        return k\n",
    "    else:  # \"mad\"\n",
    "        med = np.median(scores)\n",
    "        mad = np.median(np.abs(scores - med))\n",
    "        return med + k * 1.4826 * mad\n",
    "\n",
    "\n",
    "def _sc_diff(t, od):\n",
    "    return np.abs(np.diff(od, prepend=od[0]))\n",
    "\n",
    "def _sc_iqr_diff(t, od):\n",
    "    d = np.diff(od, prepend=od[0])\n",
    "    return np.abs(d - np.median(d))\n",
    "\n",
    "def _sc_hampel(t, od, window=15):\n",
    "    \"\"\"Per-window MAD z-score — scores are directly comparable to the fixed threshold.\"\"\"\n",
    "    n, half = len(od), window // 2\n",
    "    raw = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        nb = od[max(0, i - half): min(n, i + half + 1)]\n",
    "        med = np.median(nb)\n",
    "        mad = np.median(np.abs(nb - med))\n",
    "        if mad > 1e-12:\n",
    "            raw[i] = abs(od[i] - med) / (1.4826 * mad)\n",
    "    return raw\n",
    "\n",
    "def _sc_spline(t, od):\n",
    "    from growthcurves.non_parametric import fit_spline\n",
    "    from growthcurves.models import spline_from_params\n",
    "    result = fit_spline(t, od, smooth=\"fast\")\n",
    "    if result is None:\n",
    "        return np.zeros(len(t))\n",
    "    spl = spline_from_params(result[\"params\"])\n",
    "    return np.abs(od - np.exp(spl(t)))\n",
    "\n",
    "def _sc_iforest(t, od):\n",
    "    from sklearn.ensemble import IsolationForest\n",
    "    d = np.diff(od, prepend=od[0])\n",
    "    X = np.column_stack([od, d])\n",
    "    clf = IsolationForest(n_estimators=200, contamination=\"auto\", random_state=42)\n",
    "    clf.fit(X)\n",
    "    raw = -clf.score_samples(X)\n",
    "    return raw - raw.min()\n",
    "\n",
    "def _sc_ecod(t, od, window=15):\n",
    "    \"\"\"ECOD score using local rolling-mean residual + od + Δod.\"\"\"\n",
    "    from pyod.models.ecod import ECOD\n",
    "    n, half = len(od), window // 2\n",
    "    residual = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        win = od[max(0, i - half): min(n, i + half + 1)]\n",
    "        residual[i] = od[i] - win.mean()\n",
    "    d = np.diff(od, prepend=od[0])\n",
    "    X = np.column_stack([np.abs(residual), od, d])\n",
    "    clf = ECOD(); clf.fit(X)\n",
    "    return clf.decision_scores_\n",
    "\n",
    "def _sc_copod(t, od, window=15):\n",
    "    \"\"\"COPOD score using local rolling-mean residual + od + Δod.\"\"\"\n",
    "    from pyod.models.copod import COPOD\n",
    "    n, half = len(od), window // 2\n",
    "    residual = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        win = od[max(0, i - half): min(n, i + half + 1)]\n",
    "        residual[i] = od[i] - win.mean()\n",
    "    d = np.diff(od, prepend=od[0])\n",
    "    X = np.column_stack([np.abs(residual), od, d])\n",
    "    clf = COPOD(); clf.fit(X)\n",
    "    return clf.decision_scores_\n",
    "\n",
    "def _sc_lof(t, od):\n",
    "    from pyod.models.lof import LOF\n",
    "    d = np.diff(od, prepend=od[0])\n",
    "    X = np.column_stack([od, d])\n",
    "    clf = LOF(); clf.fit(X)\n",
    "    return clf.decision_scores_\n",
    "\n",
    "def _sc_growthcurves(t, od, window_size=15):\n",
    "    \"\"\"Distance beyond the IQR fence, in IQR units (0 for inliers).\"\"\"\n",
    "    n = len(od)\n",
    "    half = window_size // 2\n",
    "    raw = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        win = od[max(0, i - half): min(n, i + half + 1)]\n",
    "        q1 = np.nanquantile(win, 0.25)\n",
    "        q3 = np.nanquantile(win, 0.75)\n",
    "        iqr = q3 - q1\n",
    "        if iqr > 1e-12:\n",
    "            raw[i] = max(od[i] - q3, q1 - od[i], 0.0) / iqr\n",
    "    return raw\n",
    "\n",
    "SCORERS = {\n",
    "    \"z-score Δod\":      _sc_diff,\n",
    "    \"IQR Δod\":          _sc_iqr_diff,\n",
    "    \"Hampel\":           _sc_hampel,\n",
    "    \"spline residuals\": _sc_spline,\n",
    "    \"isolation forest\": _sc_iforest,\n",
    "    \"ECOD\":             _sc_ecod,\n",
    "    \"COPOD\":            _sc_copod,\n",
    "    \"LOF\":              _sc_lof,\n",
    "    \"growthcurves\":     _sc_growthcurves,\n",
    "}\n",
    "\n",
    "# ── Plot ─────────────────────────────────────────────────────────────────────\n",
    "n_sc        = len(SCORERS)\n",
    "row_heights = [3] + [2] * n_sc\n",
    "\n",
    "for cid in traces_df[\"curve_id\"].unique():\n",
    "    grp  = traces_df[traces_df[\"curve_id\"] == cid]\n",
    "    t    = grp[\"t\"].to_numpy()\n",
    "    od   = grp[\"od\"].to_numpy()\n",
    "    gt_c = gt.loc[grp.index].to_numpy()\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=1 + n_sc, cols=1,\n",
    "        shared_xaxes=True,\n",
    "        row_heights=row_heights,\n",
    "        vertical_spacing=0.02,\n",
    "    )\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=t, y=od, mode=\"lines+markers\",\n",
    "        line=dict(color=\"#CBD5E1\", width=1),\n",
    "        marker=dict(size=4, color=\"#94A3B8\"),\n",
    "        showlegend=False,\n",
    "    ), row=1, col=1)\n",
    "    if gt_c.any():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=t[gt_c], y=od[gt_c], mode=\"markers\",\n",
    "            marker=dict(size=16, symbol=\"circle-open\", color=\"black\", line=dict(width=2.5)),\n",
    "            showlegend=False,\n",
    "        ), row=1, col=1)\n",
    "\n",
    "    for j, (mname, scorer) in enumerate(SCORERS.items()):\n",
    "        row    = j + 2\n",
    "        scores = scorer(t, od)\n",
    "        color  = color_map[mname]\n",
    "        t_type, k = THRESH[mname]\n",
    "        thresh = _thresh_value(scores, t_type, k)\n",
    "\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=t, y=scores, mode=\"lines\",\n",
    "            line=dict(color=color, width=1.5),\n",
    "            fill=\"tozeroy\", fillcolor=_hex_to_rgba(color),\n",
    "            showlegend=False,\n",
    "            hovertemplate=f\"{mname}  t=%{{x:.0f}}  score=%{{y:.3g}}\"\n",
    "                          f\"  (thresh={thresh:.3g})<extra></extra>\",\n",
    "        ), row=row, col=1)\n",
    "\n",
    "        fig.add_hline(y=thresh, line=dict(color=\"red\", width=1, dash=\"dot\"),\n",
    "                      row=row, col=1)\n",
    "\n",
    "        if gt_c.any():\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=t[gt_c], y=scores[gt_c], mode=\"markers\",\n",
    "                marker=dict(size=10, symbol=\"circle-open\", color=\"black\", line=dict(width=2)),\n",
    "                showlegend=False, hoverinfo=\"skip\",\n",
    "            ), row=row, col=1)\n",
    "\n",
    "        type_label = {\"fold\": \"fold\", \"mad\": \"MAD z\", \"fixed\": \"fixed\"}[t_type]\n",
    "        fig.update_yaxes(title_text=f\"{mname} ({type_label})\", row=row, col=1,\n",
    "                         title_standoff=4, rangemode=\"tozero\")\n",
    "\n",
    "    fig.update_yaxes(title_text=\"OD\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Time\", row=1 + n_sc, col=1)\n",
    "    fig.update_layout(\n",
    "        title=f\"<b>{cid}</b>  —  raw anomaly scores  \"\n",
    "              f\"(red dash = threshold  |  ○ = ground truth)\",\n",
    "        template=\"plotly_white\",\n",
    "        height=240 + n_sc * 90,\n",
    "        width=950,\n",
    "        showlegend=False,\n",
    "        margin=dict(t=45, b=35, l=170, r=15),\n",
    "    )\n",
    "    fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "growthcurves_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
